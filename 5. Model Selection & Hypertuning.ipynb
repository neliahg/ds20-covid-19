{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc2e17f-f580-4e67-a410-612a1ff35406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost\n",
    "\n",
    "df = pd.read_pickle(r'pickles/df4.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f1fe17-470b-45ff-8782-620d2da50df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>4963.428084</td>\n",
       "      <td>70.451601</td>\n",
       "      <td>34.314958</td>\n",
       "      <td>0.468188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>1626.191070</td>\n",
       "      <td>40.326059</td>\n",
       "      <td>8.852922</td>\n",
       "      <td>0.825760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>935.848452</td>\n",
       "      <td>30.591640</td>\n",
       "      <td>7.542226</td>\n",
       "      <td>0.899728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>4289.087993</td>\n",
       "      <td>65.491129</td>\n",
       "      <td>58.546920</td>\n",
       "      <td>0.540441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>1048.414422</td>\n",
       "      <td>32.379228</td>\n",
       "      <td>8.963344</td>\n",
       "      <td>0.887667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVR</td>\n",
       "      <td>9334.276407</td>\n",
       "      <td>96.614059</td>\n",
       "      <td>21.176847</td>\n",
       "      <td>-0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>949.064758</td>\n",
       "      <td>30.806895</td>\n",
       "      <td>7.448216</td>\n",
       "      <td>0.898311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model          MSE       RMSE        MAE        R2\n",
       "0           LinearRegression  4963.428084  70.451601  34.314958  0.468188\n",
       "1      DecisionTreeRegressor  1626.191070  40.326059   8.852922  0.825760\n",
       "2      RandomForestRegressor   935.848452  30.591640   7.542226  0.899728\n",
       "3          AdaBoostRegressor  4289.087993  65.491129  58.546920  0.540441\n",
       "4  GradientBoostingRegressor  1048.414422  32.379228   8.963344  0.887667\n",
       "5                        SVR  9334.276407  96.614059  21.176847 -0.000131\n",
       "6               XGBRegressor   949.064758  30.806895   7.448216  0.898311"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model selection using regression models\n",
    "\n",
    "y=df['New Deaths']\n",
    "X = df.drop(columns=['New Deaths'])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)\n",
    "\n",
    "# --- metrics function ---\n",
    "def regressionMetrics(y, yhat):\n",
    "    res = {\n",
    "        'MSE': metrics.mean_squared_error(y, yhat),\n",
    "        'RMSE': np.sqrt(metrics.mean_squared_error(y, yhat)),\n",
    "        'MAE': metrics.mean_absolute_error(y, yhat),\n",
    "        #'RMSLE': np.sqrt(metrics.mean_squared_log_error(y, yhat)), removed due to -1 error\n",
    "        'R2': metrics.r2_score(y, yhat)\n",
    "    }\n",
    "    return res\n",
    "\n",
    "# --- models dictionary ---\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(),\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(),\n",
    "    \"SVR\": SVR(),\n",
    "    \"XGBRegressor\": xgboost.XGBRegressor(objective=\"reg:squarederror\")\n",
    "}\n",
    "\n",
    "# --- train, predict, and evaluate on DEV set ---\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_dev_pred = model.predict(X_dev)\n",
    "    m = regressionMetrics(y_dev, y_dev_pred)\n",
    "    results.append({\"Model\": name, **m})\n",
    "\n",
    "# --- results table ---\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c66a446-ae0f-445c-9c6a-086790c60c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_excel('output1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ad3522-937b-45ab-aec4-8956fb8f498f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [100, 200, 300, 500, 800, 1000],\n",
       " 'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
       " 'max_depth': [3, 5, 7, 9, 11],\n",
       " 'min_child_weight': [1, 3, 5, 7],\n",
       " 'subsample': [0.6, 0.8, 1.0],\n",
       " 'colsample_bytree': [0.6, 0.8, 1.0],\n",
       " 'reg_lambda': [0.1, 1.0, 5.0, 10.0],\n",
       " 'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
       " 'booster': ['gbtree'],\n",
       " 'random_state': [42]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find best parameters for xgboost\n",
    "\n",
    "import numpy as np\n",
    "import xgboost\n",
    "\n",
    "# --- parameter grid for XGBoost ---\n",
    "xgb_param_grid = {\n",
    "    # number of boosting rounds (trees)\n",
    "    'n_estimators': [100, 200, 300, 500, 800, 1000],\n",
    "    \n",
    "    # learning rate (controls contribution of each tree)\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    \n",
    "    # max depth of each tree\n",
    "    'max_depth': [3, 5, 7, 9, 11],\n",
    "    \n",
    "    # minimum sum of instance weight (hessian) needed in a child\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    \n",
    "    # subsample ratio of the training instances (stochastic sampling)\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    \n",
    "    # subsample ratio of columns when constructing each tree\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    \n",
    "    # L2 regularization term\n",
    "    'reg_lambda': [0.1, 1.0, 5.0, 10.0],\n",
    "    \n",
    "    # L1 regularization term\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
    "    \n",
    "    # type of booster (usually “gbtree” is best for regression)\n",
    "    'booster': ['gbtree'],\n",
    "    \n",
    "    # random seed for reproducibility\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "xgb_param_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a72130ac-7c54-4792-92e7-d20a53a74d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best parameters found:  {'subsample': 1.0, 'reg_lambda': 10.0, 'reg_alpha': 0, 'random_state': 42, 'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 7, 'learning_rate': 0.01, 'colsample_bytree': 0.6, 'booster': 'gbtree'}\n",
      "Best R² Score:  0.8465584715207418\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "xgb_random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=xgb_param_grid,\n",
    "    n_iter=50,                    # number of random combinations\n",
    "    scoring='r2',                 # use R² for evaluation\n",
    "    cv=3,                         # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1                     # use all cores\n",
    ")\n",
    "\n",
    "xgb_random_search.fit(X_train, y_train)\n",
    "print(\"Best parameters found: \", xgb_random_search.best_params_)\n",
    "print(\"Best R² Score: \", xgb_random_search.best_score_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
